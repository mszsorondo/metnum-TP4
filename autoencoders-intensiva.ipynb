{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-05T18:33:03.743899Z","iopub.execute_input":"2021-11-05T18:33:03.744200Z","iopub.status.idle":"2021-11-05T18:33:03.762557Z","shell.execute_reply.started":"2021-11-05T18:33:03.744121Z","shell.execute_reply":"2021-11-05T18:33:03.761554Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from autoencoders import autoencoder\nimport tensorflow as tf\n\n(x_train, y_train), (x_val, y_val) = tf.keras.datasets.fashion_mnist.load_data()\n\n\nmodelDepths_100 = [[100], [392,100,392],[392,196,100,196,392]]\n\nmodelDepths_75 = [[75],[588,75,588] ,[588,441,75,441,588],[588,441,330,75,330,441,588],\n                  [588,441,330,250,75,250,330,441,588]]\n\nmodelDepths_50 = [[50],[392,50,392] ,[392,196,50,196,392],[392,196,100,50,100,196,392],[392,196,100,75,50,75,100,196,392]]\n\nmodelDepths_25 = [[25],[392,25,392],[392,196,25,196,392],[392,196,100,25,100,196,392],[392,196,100,50,25,50,100,196,392]]\n\nmodelDepths_15 = [[15], [392,15,392], [392,196,15,196,392],[392,196,50,15,50,196,392],[392,196,50,25,15,25,50,196,392],[392,196,100,50,25,15,25,50,100,196,392]]\n\nmodelDepths_5 = [[5], [200,5,200], [200,50,5,50,200],[50,25,10,5,10,25,50],[100,50,25,10,5,10,25,50,100],[392,196,100,50,25,5,25,50,100,196,392] ,[392,196,100,50,25,10,5,10,25,50,100,196,392]]\n","metadata":{"execution":{"iopub.status.busy":"2021-11-05T18:33:03.764312Z","iopub.execute_input":"2021-11-05T18:33:03.764578Z","iopub.status.idle":"2021-11-05T18:33:10.163613Z","shell.execute_reply.started":"2021-11-05T18:33:03.764544Z","shell.execute_reply":"2021-11-05T18:33:10.162782Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"new\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n32768/29515 [=================================] - 0s 0us/step\n40960/29515 [=========================================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n26427392/26421880 [==============================] - 0s 0us/step\n26435584/26421880 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n16384/5148 [===============================================================================================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n4423680/4422102 [==============================] - 0s 0us/step\n4431872/4422102 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"def multipleModels(seqDepths, X_train, X_val, y_train, y_val):\n  #given a sequence of autoencoder dephts, creates and trains the autoencoder and KNN the classifier\n  #returns a sequence with respective trained models\n  res = []\n  for arq in seqDepths:\n    res.append(autoencoder(arq, arq[int(len(arq)/2)], 'relu'))\n    res[-1].construct()\n    res[-1].trainAndReduce(X_train, X_val)\n    res[-1].diagnose(y_train,y_val,15)\n  \n  return res\n","metadata":{"execution":{"iopub.status.busy":"2021-11-05T18:33:10.164819Z","iopub.execute_input":"2021-11-05T18:33:10.165455Z","iopub.status.idle":"2021-11-05T18:33:10.174380Z","shell.execute_reply.started":"2021-11-05T18:33:10.165414Z","shell.execute_reply":"2021-11-05T18:33:10.173245Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"models_100 = multipleModels(modelDepths_100, x_train,x_val,y_train, y_val)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-05T18:33:10.176149Z","iopub.execute_input":"2021-11-05T18:33:10.176401Z","iopub.status.idle":"2021-11-05T18:39:01.455194Z","shell.execute_reply.started":"2021-11-05T18:33:10.176370Z","shell.execute_reply":"2021-11-05T18:39:01.454428Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2021-11-05 18:33:10.430957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-11-05 18:33:10.534947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-11-05 18:33:10.535680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-11-05 18:33:10.536845: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-11-05 18:33:10.537596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-11-05 18:33:10.538287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-11-05 18:33:10.539065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-11-05 18:33:12.379579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-11-05 18:33:12.380387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-11-05 18:33:12.381093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-11-05 18:33:12.381799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n2021-11-05 18:33:13.504803: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n235/235 [==============================] - 2s 4ms/step - loss: 0.0473 - val_loss: 0.0258\nEpoch 2/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0210 - val_loss: 0.0174\nEpoch 3/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0153 - val_loss: 0.0138\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0127 - val_loss: 0.0120\nEpoch 5/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0108\nEpoch 6/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0100\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0096 - val_loss: 0.0095\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0091 - val_loss: 0.0090\nEpoch 9/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0087 - val_loss: 0.0086\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0083 - val_loss: 0.0083\nEpoch 11/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0080 - val_loss: 0.0080\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0078\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0076 - val_loss: 0.0076\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0075 - val_loss: 0.0075\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0074\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0073\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0072\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0071\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0071\nEpoch 20/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0070\nEpoch 21/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0069\nEpoch 22/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0069\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0069\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0068\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0068\nEpoch 26/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0066 - val_loss: 0.0068\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0066 - val_loss: 0.0067\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0066 - val_loss: 0.0067\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0065 - val_loss: 0.0067\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0065 - val_loss: 0.0067\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0065 - val_loss: 0.0066\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0065 - val_loss: 0.0066\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0065 - val_loss: 0.0066\nEpoch 34/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0066\nEpoch 35/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0066\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0065\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0065\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0065\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0065\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0066\nEpoch 41/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0065\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0065\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0065\nEpoch 44/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0065\nEpoch 45/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0065\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0065\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0064\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0064\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0064\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0064\n\nautoencoder training time:  36.25324821472168 \n\n\n  (10000, 100)\n\n  (10000, 100)\n\n KNN training+prediction time:  67.11266374588013  , k =  15 \n\n\n Accuracy score :  0.8563\nEpoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0361 - val_loss: 0.0198\nEpoch 2/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0163 - val_loss: 0.0143\nEpoch 3/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0133 - val_loss: 0.0127\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0118 - val_loss: 0.0110\nEpoch 5/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0105 - val_loss: 0.0102\nEpoch 6/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0095\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0092 - val_loss: 0.0093\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0088 - val_loss: 0.0087\nEpoch 9/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0084 - val_loss: 0.0083\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0081 - val_loss: 0.0081\nEpoch 11/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0078 - val_loss: 0.0078\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0076 - val_loss: 0.0078\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0074 - val_loss: 0.0074\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0073\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0073\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0070\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0070\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0067\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0065 - val_loss: 0.0066\nEpoch 20/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0065 - val_loss: 0.0066\nEpoch 21/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0065\nEpoch 22/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0064\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0062 - val_loss: 0.0065\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0062\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0060 - val_loss: 0.0062\nEpoch 26/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0060 - val_loss: 0.0062\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0060 - val_loss: 0.0062\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0059 - val_loss: 0.0062\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0058 - val_loss: 0.0061\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0058 - val_loss: 0.0061\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0057 - val_loss: 0.0064\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0057 - val_loss: 0.0059\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0057 - val_loss: 0.0059\nEpoch 34/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0056 - val_loss: 0.0058\nEpoch 35/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0056 - val_loss: 0.0060\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0055 - val_loss: 0.0058\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0055 - val_loss: 0.0057\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0055 - val_loss: 0.0057\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0055 - val_loss: 0.0057\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0054 - val_loss: 0.0056\nEpoch 41/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0054 - val_loss: 0.0057\nEpoch 42/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0054 - val_loss: 0.0057\nEpoch 43/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0053 - val_loss: 0.0056\nEpoch 44/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0053 - val_loss: 0.0056\nEpoch 45/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0053 - val_loss: 0.0055\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0053 - val_loss: 0.0055\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0052 - val_loss: 0.0055\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0052 - val_loss: 0.0055\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0052 - val_loss: 0.0054\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0052 - val_loss: 0.0055\n\nautoencoder training time:  42.13550901412964 \n\n\n  (10000, 100)\n\n  (10000, 100)\n\n KNN training+prediction time:  76.67883515357971  , k =  15 \n\n\n Accuracy score :  0.8589\nEpoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0379 - val_loss: 0.0229\nEpoch 2/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0185 - val_loss: 0.0163\nEpoch 3/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0153 - val_loss: 0.0142\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0137 - val_loss: 0.0131\nEpoch 5/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0126 - val_loss: 0.0124\nEpoch 6/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0118 - val_loss: 0.0115\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0112 - val_loss: 0.0109\nEpoch 8/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0106 - val_loss: 0.0106\nEpoch 9/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0102 - val_loss: 0.0101\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0098\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0095 - val_loss: 0.0098\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0093 - val_loss: 0.0093\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0090 - val_loss: 0.0090\nEpoch 14/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0088 - val_loss: 0.0090\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0086 - val_loss: 0.0086\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0084 - val_loss: 0.0085\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0082 - val_loss: 0.0086\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0081 - val_loss: 0.0082\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0082\nEpoch 20/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0080\nEpoch 21/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0076 - val_loss: 0.0080\nEpoch 22/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0076 - val_loss: 0.0077\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0075 - val_loss: 0.0077\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0075\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0074\nEpoch 26/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0076\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0072\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0072\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0071\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0071\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0071\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0069\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0066 - val_loss: 0.0070\nEpoch 34/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0066 - val_loss: 0.0069\nEpoch 35/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0065 - val_loss: 0.0067\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0065 - val_loss: 0.0068\nEpoch 37/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0067\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0066\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0065\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0066\nEpoch 41/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0062 - val_loss: 0.0066\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0062 - val_loss: 0.0064\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0062 - val_loss: 0.0065\nEpoch 44/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0061 - val_loss: 0.0064\nEpoch 45/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0061 - val_loss: 0.0063\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0060 - val_loss: 0.0063\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0060 - val_loss: 0.0063\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0059 - val_loss: 0.0062\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0060 - val_loss: 0.0062\nEpoch 50/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0059 - val_loss: 0.0061\n\nautoencoder training time:  39.964831590652466 \n\n\n  (10000, 100)\n\n  (10000, 100)\n\n KNN training+prediction time:  76.47675228118896  , k =  15 \n\n\n Accuracy score :  0.8657\n","output_type":"stream"}]},{"cell_type":"code","source":"models_75 = multipleModels(modelDepths_75, x_train,x_val,y_train,y_val)\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-05T18:39:01.456396Z","iopub.execute_input":"2021-11-05T18:39:01.456741Z","iopub.status.idle":"2021-11-05T18:48:03.400723Z","shell.execute_reply.started":"2021-11-05T18:39:01.456691Z","shell.execute_reply":"2021-11-05T18:48:03.399926Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0508 - val_loss: 0.0281\nEpoch 2/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0232 - val_loss: 0.0194\nEpoch 3/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0170 - val_loss: 0.0155\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0141 - val_loss: 0.0133\nEpoch 5/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0125 - val_loss: 0.0119\nEpoch 6/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0111\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0104\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0100\nEpoch 9/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0097\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0095 - val_loss: 0.0094\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0093 - val_loss: 0.0092\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0091 - val_loss: 0.0091\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0089 - val_loss: 0.0089\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0088 - val_loss: 0.0087\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0086 - val_loss: 0.0086\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0085 - val_loss: 0.0085\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0084 - val_loss: 0.0085\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0083 - val_loss: 0.0084\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0083 - val_loss: 0.0083\nEpoch 20/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0082 - val_loss: 0.0083\nEpoch 21/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0082 - val_loss: 0.0083\nEpoch 22/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0081 - val_loss: 0.0083\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0081 - val_loss: 0.0082\nEpoch 24/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0081 - val_loss: 0.0082\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0080 - val_loss: 0.0081\nEpoch 26/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0080 - val_loss: 0.0081\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0080 - val_loss: 0.0081\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0080 - val_loss: 0.0081\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0081\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0081\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0080\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0080\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0080\nEpoch 34/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0081\nEpoch 35/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0080\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0079\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0079\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0079\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0079\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0079\nEpoch 41/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0080\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0079\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0079\nEpoch 44/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0079\nEpoch 45/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0079\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0078\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0079\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0079\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0078\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0078\n\nautoencoder training time:  41.847050189971924 \n\n\n  (10000, 75)\n\n  (10000, 75)\n\n KNN training+prediction time:  38.83674740791321  , k =  15 \n\n\n Accuracy score :  0.8546\nEpoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0349 - val_loss: 0.0185\nEpoch 2/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0159 - val_loss: 0.0137\nEpoch 3/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0129 - val_loss: 0.0120\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0111 - val_loss: 0.0113\nEpoch 5/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0100\nEpoch 6/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0095 - val_loss: 0.0093\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0090 - val_loss: 0.0088\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0086 - val_loss: 0.0085\nEpoch 9/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0082 - val_loss: 0.0083\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0080 - val_loss: 0.0081\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0079\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0075 - val_loss: 0.0076\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0075 - val_loss: 0.0075\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0073\nEpoch 15/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0070 - val_loss: 0.0071\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0071\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0070\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0071\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0068\nEpoch 20/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0066 - val_loss: 0.0067\nEpoch 21/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0065 - val_loss: 0.0067\nEpoch 22/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0066\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0067\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0065\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0065\nEpoch 26/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0062 - val_loss: 0.0064\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0061 - val_loss: 0.0064\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0061 - val_loss: 0.0063\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0061 - val_loss: 0.0063\nEpoch 30/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0060 - val_loss: 0.0063\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0060 - val_loss: 0.0062\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0059 - val_loss: 0.0067\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0059 - val_loss: 0.0061\nEpoch 34/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0058 - val_loss: 0.0061\nEpoch 35/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0058 - val_loss: 0.0061\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0058 - val_loss: 0.0060\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0057 - val_loss: 0.0060\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0057 - val_loss: 0.0060\nEpoch 39/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0057 - val_loss: 0.0061\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0057 - val_loss: 0.0059\nEpoch 41/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0056 - val_loss: 0.0059\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0056 - val_loss: 0.0060\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0056 - val_loss: 0.0061\nEpoch 44/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0056 - val_loss: 0.0059\nEpoch 45/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0055 - val_loss: 0.0059\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0055 - val_loss: 0.0059\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0055 - val_loss: 0.0058\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0055 - val_loss: 0.0059\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0054 - val_loss: 0.0058\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0054 - val_loss: 0.0057\n\nautoencoder training time:  42.09298753738403 \n\n\n  (10000, 75)\n\n  (10000, 75)\n\n KNN training+prediction time:  52.5037145614624  , k =  15 \n\n\n Accuracy score :  0.8643\nEpoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0363 - val_loss: 0.0205\nEpoch 2/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0179 - val_loss: 0.0165\nEpoch 3/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0147 - val_loss: 0.0136\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0128 - val_loss: 0.0123\nEpoch 5/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0118 - val_loss: 0.0113\nEpoch 6/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0110 - val_loss: 0.0110\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0101\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0097\nEpoch 9/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0095\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0091 - val_loss: 0.0090\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0087 - val_loss: 0.0088\nEpoch 12/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0086\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0083 - val_loss: 0.0083\nEpoch 14/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0080 - val_loss: 0.0082\nEpoch 15/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0079 - val_loss: 0.0079\nEpoch 16/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0077 - val_loss: 0.0078\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0076 - val_loss: 0.0077\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0075\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0075\nEpoch 20/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0073\nEpoch 21/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0072\nEpoch 22/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0072\nEpoch 23/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0073\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0071\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0070\nEpoch 26/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0071\nEpoch 27/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0069\nEpoch 28/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0074\nEpoch 29/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0067\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0068\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0067\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0067\nEpoch 33/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0063 - val_loss: 0.0067\nEpoch 34/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0063 - val_loss: 0.0067\nEpoch 35/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0063 - val_loss: 0.0066\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0062 - val_loss: 0.0067\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0062 - val_loss: 0.0066\nEpoch 38/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0061 - val_loss: 0.0066\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0061 - val_loss: 0.0065\nEpoch 40/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0061 - val_loss: 0.0064\nEpoch 41/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0060 - val_loss: 0.0065\nEpoch 42/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0060 - val_loss: 0.0065\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0060 - val_loss: 0.0065\nEpoch 44/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0060 - val_loss: 0.0063\nEpoch 45/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0059 - val_loss: 0.0064\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0059 - val_loss: 0.0064\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0059 - val_loss: 0.0063\nEpoch 48/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0058 - val_loss: 0.0065\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0059 - val_loss: 0.0064\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0058 - val_loss: 0.0068\n\nautoencoder training time:  42.7078902721405 \n\n\n  (10000, 75)\n\n  (10000, 75)\n\n KNN training+prediction time:  61.30067491531372  , k =  15 \n\n\n Accuracy score :  0.8684\nEpoch 1/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0414 - val_loss: 0.0236\nEpoch 2/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0205 - val_loss: 0.0181\nEpoch 3/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0172 - val_loss: 0.0162\nEpoch 4/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0153 - val_loss: 0.0146\nEpoch 5/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0137\nEpoch 6/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0133 - val_loss: 0.0130\nEpoch 7/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0126 - val_loss: 0.0123\nEpoch 8/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0120 - val_loss: 0.0119\nEpoch 9/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0113\nEpoch 10/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0111 - val_loss: 0.0112\nEpoch 11/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0108\nEpoch 12/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0110\nEpoch 13/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0102 - val_loss: 0.0104\nEpoch 14/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0099 - val_loss: 0.0108\nEpoch 15/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0100\nEpoch 16/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 17/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0096\nEpoch 18/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0094\nEpoch 19/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0093\nEpoch 20/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0088 - val_loss: 0.0091\nEpoch 21/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0091\nEpoch 22/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0085 - val_loss: 0.0089\nEpoch 23/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0087\nEpoch 24/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0083 - val_loss: 0.0087\nEpoch 25/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0081 - val_loss: 0.0085\nEpoch 26/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0081 - val_loss: 0.0084\nEpoch 27/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0079 - val_loss: 0.0087\nEpoch 28/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0079 - val_loss: 0.0083\nEpoch 29/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0078 - val_loss: 0.0082\nEpoch 30/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0077 - val_loss: 0.0081\nEpoch 31/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0076 - val_loss: 0.0081\nEpoch 32/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0075 - val_loss: 0.0080\nEpoch 33/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0075 - val_loss: 0.0079\nEpoch 34/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0074 - val_loss: 0.0079\nEpoch 35/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0073 - val_loss: 0.0077\nEpoch 36/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0073 - val_loss: 0.0077\nEpoch 37/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0072 - val_loss: 0.0077\nEpoch 38/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0071 - val_loss: 0.0077\nEpoch 39/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0071 - val_loss: 0.0080\nEpoch 40/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0070 - val_loss: 0.0076\nEpoch 41/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0070 - val_loss: 0.0078\nEpoch 42/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0074\nEpoch 43/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0075\nEpoch 44/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0074\nEpoch 45/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0079\nEpoch 46/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0074\nEpoch 47/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0073\nEpoch 48/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0073\nEpoch 49/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0072\nEpoch 50/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0072\n\nautoencoder training time:  82.99382591247559 \n\n\n  (10000, 75)\n\n  (10000, 75)\n\n KNN training+prediction time:  69.8926453590393  , k =  15 \n\n\n Accuracy score :  0.8715\nEpoch 1/50\n235/235 [==============================] - 2s 5ms/step - loss: 0.0460 - val_loss: 0.0266\nEpoch 2/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0233 - val_loss: 0.0214\nEpoch 3/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0201 - val_loss: 0.0193\nEpoch 4/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0184 - val_loss: 0.0184\nEpoch 5/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0175 - val_loss: 0.0170\nEpoch 6/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0165 - val_loss: 0.0159\nEpoch 7/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0155 - val_loss: 0.0150\nEpoch 8/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0147 - val_loss: 0.0147\nEpoch 9/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0141 - val_loss: 0.0140\nEpoch 10/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0138\nEpoch 11/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0132 - val_loss: 0.0132\nEpoch 12/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0130\nEpoch 13/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0125 - val_loss: 0.0128\nEpoch 14/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0121 - val_loss: 0.0125\nEpoch 15/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0119 - val_loss: 0.0122\nEpoch 16/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0119\nEpoch 17/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0116\nEpoch 18/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0115\nEpoch 19/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0113\nEpoch 20/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0112\nEpoch 21/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0107 - val_loss: 0.0111\nEpoch 22/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0106 - val_loss: 0.0110\nEpoch 23/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0110\nEpoch 24/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0103 - val_loss: 0.0107\nEpoch 25/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0102 - val_loss: 0.0112\nEpoch 26/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0104\nEpoch 27/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0099 - val_loss: 0.0104\nEpoch 28/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0103\nEpoch 29/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0102\nEpoch 30/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0103\nEpoch 31/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0100\nEpoch 32/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0100\nEpoch 33/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0099\nEpoch 34/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0103\nEpoch 35/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0098\nEpoch 36/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0090 - val_loss: 0.0096\nEpoch 37/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0090 - val_loss: 0.0095\nEpoch 38/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0095\nEpoch 39/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0088 - val_loss: 0.0093\nEpoch 40/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0088 - val_loss: 0.0093\nEpoch 41/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0087 - val_loss: 0.0093\nEpoch 42/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0094\nEpoch 43/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0093\nEpoch 44/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0092\nEpoch 45/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0085 - val_loss: 0.0093\nEpoch 46/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0092\nEpoch 47/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0093\nEpoch 48/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0083 - val_loss: 0.0091\nEpoch 49/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0083 - val_loss: 0.0091\nEpoch 50/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0082 - val_loss: 0.0089\n\nautoencoder training time:  46.70902943611145 \n\n\n  (10000, 75)\n\n  (10000, 75)\n\n KNN training+prediction time:  47.55479431152344  , k =  15 \n\n\n Accuracy score :  0.8679\n","output_type":"stream"}]},{"cell_type":"code","source":"models_50 = multipleModels(modelDepths_50, x_train,x_val,y_train,y_val)\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-05T18:48:03.401929Z","iopub.execute_input":"2021-11-05T18:48:03.403504Z","iopub.status.idle":"2021-11-05T18:53:42.098563Z","shell.execute_reply.started":"2021-11-05T18:48:03.403454Z","shell.execute_reply":"2021-11-05T18:53:42.097120Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Epoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0545 - val_loss: 0.0298\nEpoch 2/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0253 - val_loss: 0.0220\nEpoch 3/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0196 - val_loss: 0.0177\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0161 - val_loss: 0.0150\nEpoch 5/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0136\nEpoch 6/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0131 - val_loss: 0.0127\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0124 - val_loss: 0.0122\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0119 - val_loss: 0.0117\nEpoch 9/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0114\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0112 - val_loss: 0.0112\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0110 - val_loss: 0.0110\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0108 - val_loss: 0.0109\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0108\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0106 - val_loss: 0.0106\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0104 - val_loss: 0.0105\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0104 - val_loss: 0.0105\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0104\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0104\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0103\nEpoch 20/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0104\nEpoch 21/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0101 - val_loss: 0.0102\nEpoch 22/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0101 - val_loss: 0.0102\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0101 - val_loss: 0.0102\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0102\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0101\nEpoch 26/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0101\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0101\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0101\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0100\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0100\nEpoch 31/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0099 - val_loss: 0.0100\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0100\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0100\nEpoch 34/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0100\nEpoch 35/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0100\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0100\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0100\nEpoch 38/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0099\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0100\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0100\nEpoch 41/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0099\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0099\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0100\nEpoch 44/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0099\nEpoch 45/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0099\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0099\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0100\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0097 - val_loss: 0.0099\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0097 - val_loss: 0.0099\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0097 - val_loss: 0.0099\n\nautoencoder training time:  41.85452437400818 \n\n\n  (10000, 50)\n\n  (10000, 50)\n\n KNN training+prediction time:  23.63592791557312  , k =  15 \n\n\n Accuracy score :  0.8536\nEpoch 1/50\n235/235 [==============================] - 2s 4ms/step - loss: 0.0377 - val_loss: 0.0203\nEpoch 2/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0173 - val_loss: 0.0158\nEpoch 3/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0132\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0126 - val_loss: 0.0120\nEpoch 5/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0117 - val_loss: 0.0114\nEpoch 6/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0109 - val_loss: 0.0109\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0105 - val_loss: 0.0108\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0101 - val_loss: 0.0100\nEpoch 9/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0097\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0095 - val_loss: 0.0095\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0093 - val_loss: 0.0097\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0091 - val_loss: 0.0094\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0089 - val_loss: 0.0091\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0087 - val_loss: 0.0088\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0086 - val_loss: 0.0088\nEpoch 16/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0086\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0083 - val_loss: 0.0087\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0082 - val_loss: 0.0085\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0082 - val_loss: 0.0083\nEpoch 20/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0081 - val_loss: 0.0083\nEpoch 21/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0080 - val_loss: 0.0082\nEpoch 22/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0079 - val_loss: 0.0081\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0080\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0080\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0080\nEpoch 26/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0079\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0075 - val_loss: 0.0078\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0075 - val_loss: 0.0080\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0075 - val_loss: 0.0077\nEpoch 30/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0075 - val_loss: 0.0079\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0074 - val_loss: 0.0077\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0074 - val_loss: 0.0077\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0078\nEpoch 34/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0076\nEpoch 35/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0075\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0075\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0077\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0074\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0074\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0078\nEpoch 41/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0074\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0075\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0074\nEpoch 44/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0070 - val_loss: 0.0073\nEpoch 45/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0073\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0072\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0074\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0072\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0072\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0073\n\nautoencoder training time:  40.05342435836792 \n\n\n  (10000, 50)\n\n  (10000, 50)\n\n KNN training+prediction time:  20.4070041179657  , k =  15 \n\n\n Accuracy score :  0.8632\nEpoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0391 - val_loss: 0.0214\nEpoch 2/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0189 - val_loss: 0.0169\nEpoch 3/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0160 - val_loss: 0.0150\nEpoch 4/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0136\nEpoch 5/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0131 - val_loss: 0.0129\nEpoch 6/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0121\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0116\nEpoch 8/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0111 - val_loss: 0.0112\nEpoch 9/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0107\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0105\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0102\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0099\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0095 - val_loss: 0.0096\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0093 - val_loss: 0.0095\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0092 - val_loss: 0.0094\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0090 - val_loss: 0.0103\nEpoch 17/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0093\nEpoch 18/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0087 - val_loss: 0.0088\nEpoch 19/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0088\nEpoch 20/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0085 - val_loss: 0.0088\nEpoch 21/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0086\nEpoch 22/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0083 - val_loss: 0.0085\nEpoch 23/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0082 - val_loss: 0.0086\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0081 - val_loss: 0.0088\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0080 - val_loss: 0.0082\nEpoch 26/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0086\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0081\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0082\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0079\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0079\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0076 - val_loss: 0.0080\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0076 - val_loss: 0.0078\nEpoch 33/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0078\nEpoch 34/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0075 - val_loss: 0.0077\nEpoch 35/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0075 - val_loss: 0.0077\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0074 - val_loss: 0.0079\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0074 - val_loss: 0.0076\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0076\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0076\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0076\nEpoch 41/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0075\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0076\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0075\nEpoch 44/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0075\nEpoch 45/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0076\nEpoch 46/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0071 - val_loss: 0.0074\nEpoch 47/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0070 - val_loss: 0.0073\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0073\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0074\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0074\n\nautoencoder training time:  41.628926515579224 \n\n\n  (10000, 50)\n\n  (10000, 50)\n\n KNN training+prediction time:  28.124051094055176  , k =  15 \n\n\n Accuracy score :  0.8652\nEpoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0436 - val_loss: 0.0251\nEpoch 2/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0216 - val_loss: 0.0194\nEpoch 3/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0182 - val_loss: 0.0174\nEpoch 4/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0164 - val_loss: 0.0164\nEpoch 5/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0152 - val_loss: 0.0147\nEpoch 6/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0144 - val_loss: 0.0140\nEpoch 7/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0135\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0132 - val_loss: 0.0131\nEpoch 9/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0128\nEpoch 10/50\n235/235 [==============================] - 1s 6ms/step - loss: 0.0124 - val_loss: 0.0124\nEpoch 11/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0121 - val_loss: 0.0121\nEpoch 12/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0118 - val_loss: 0.0119\nEpoch 13/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0114\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0113\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0111 - val_loss: 0.0112\nEpoch 16/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0110\nEpoch 17/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0107 - val_loss: 0.0108\nEpoch 18/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0108\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0104 - val_loss: 0.0105\nEpoch 20/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0102 - val_loss: 0.0106\nEpoch 21/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0102\nEpoch 22/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0100 - val_loss: 0.0101\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0102\nEpoch 24/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0105\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0097 - val_loss: 0.0100\nEpoch 26/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0099\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0094 - val_loss: 0.0098\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0093 - val_loss: 0.0097\nEpoch 30/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0095\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0091 - val_loss: 0.0094\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0091 - val_loss: 0.0094\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0090 - val_loss: 0.0092\nEpoch 34/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0093\nEpoch 35/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0089 - val_loss: 0.0091\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0088 - val_loss: 0.0096\nEpoch 37/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0087 - val_loss: 0.0092\nEpoch 38/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0087 - val_loss: 0.0091\nEpoch 39/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0090\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0086 - val_loss: 0.0088\nEpoch 41/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0085 - val_loss: 0.0089\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0084 - val_loss: 0.0088\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0084 - val_loss: 0.0088\nEpoch 44/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0088\nEpoch 45/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0083 - val_loss: 0.0089\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0083 - val_loss: 0.0086\nEpoch 47/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0082 - val_loss: 0.0089\nEpoch 48/50\n235/235 [==============================] - 1s 6ms/step - loss: 0.0082 - val_loss: 0.0086\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0082 - val_loss: 0.0086\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0081 - val_loss: 0.0086\n\nautoencoder training time:  44.60466289520264 \n\n\n  (10000, 50)\n\n  (10000, 50)\n\n KNN training+prediction time:  19.4036066532135  , k =  15 \n\n\n Accuracy score :  0.8664\nEpoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0467 - val_loss: 0.0267\nEpoch 2/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0229 - val_loss: 0.0207\nEpoch 3/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0197 - val_loss: 0.0187\nEpoch 4/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0182 - val_loss: 0.0185\nEpoch 5/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0173 - val_loss: 0.0174\nEpoch 6/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0164 - val_loss: 0.0168\nEpoch 7/50\n235/235 [==============================] - 2s 7ms/step - loss: 0.0158 - val_loss: 0.0154\nEpoch 8/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0151 - val_loss: 0.0151\nEpoch 9/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0146 - val_loss: 0.0143\nEpoch 10/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0141 - val_loss: 0.0141\nEpoch 11/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0140\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0134 - val_loss: 0.0136\nEpoch 13/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0131 - val_loss: 0.0132\nEpoch 14/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0130\nEpoch 15/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0126 - val_loss: 0.0129\nEpoch 16/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0126\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0122 - val_loss: 0.0122\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0120 - val_loss: 0.0120\nEpoch 19/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0118 - val_loss: 0.0121\nEpoch 20/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0116 - val_loss: 0.0121\nEpoch 21/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0116\nEpoch 22/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0113 - val_loss: 0.0115\nEpoch 23/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0114\nEpoch 24/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0111 - val_loss: 0.0116\nEpoch 25/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0115\nEpoch 26/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0112\nEpoch 27/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0110\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0109\nEpoch 29/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0106 - val_loss: 0.0107\nEpoch 30/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0109\nEpoch 31/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0107\nEpoch 32/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0103 - val_loss: 0.0107\nEpoch 33/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0102 - val_loss: 0.0105\nEpoch 34/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0105\nEpoch 35/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0104\nEpoch 36/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0100 - val_loss: 0.0103\nEpoch 37/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0100 - val_loss: 0.0103\nEpoch 38/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0099 - val_loss: 0.0102\nEpoch 39/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0102\nEpoch 40/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0102\nEpoch 41/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0100\nEpoch 42/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0101\nEpoch 43/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0099\nEpoch 44/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0099\nEpoch 45/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0095 - val_loss: 0.0100\nEpoch 46/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0098\nEpoch 47/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0099\nEpoch 48/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0098\nEpoch 49/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0096\nEpoch 50/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0097\n\nautoencoder training time:  46.61647987365723 \n\n\n  (10000, 50)\n\n  (10000, 50)\n\n KNN training+prediction time:  16.47941756248474  , k =  15 \n\n\n Accuracy score :  0.861\n","output_type":"stream"}]},{"cell_type":"code","source":"models_25 = multipleModels(modelDepths_25, x_train,x_val,y_train,y_val)\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-05T18:53:42.099813Z","iopub.execute_input":"2021-11-05T18:53:42.100062Z","iopub.status.idle":"2021-11-05T18:58:31.876727Z","shell.execute_reply.started":"2021-11-05T18:53:42.100028Z","shell.execute_reply":"2021-11-05T18:58:31.875969Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0646 - val_loss: 0.0374\nEpoch 2/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0322 - val_loss: 0.0284\nEpoch 3/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0261 - val_loss: 0.0243\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0228 - val_loss: 0.0215\nEpoch 5/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0203 - val_loss: 0.0193\nEpoch 6/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0185 - val_loss: 0.0179\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0172 - val_loss: 0.0168\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0165 - val_loss: 0.0163\nEpoch 9/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0162 - val_loss: 0.0161\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0159 - val_loss: 0.0159\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0158 - val_loss: 0.0158\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0155 - val_loss: 0.0154\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0153 - val_loss: 0.0153\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0152 - val_loss: 0.0152\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0151 - val_loss: 0.0151\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0150 - val_loss: 0.0151\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0150 - val_loss: 0.0150\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0149 - val_loss: 0.0150\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0149 - val_loss: 0.0149\nEpoch 20/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0147 - val_loss: 0.0147\nEpoch 21/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0146 - val_loss: 0.0146\nEpoch 22/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0145 - val_loss: 0.0146\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0145 - val_loss: 0.0146\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0145 - val_loss: 0.0146\nEpoch 25/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0144 - val_loss: 0.0145\nEpoch 26/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0144 - val_loss: 0.0145\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0144 - val_loss: 0.0145\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0144 - val_loss: 0.0145\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0144 - val_loss: 0.0145\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0143 - val_loss: 0.0144\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0143 - val_loss: 0.0145\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0143 - val_loss: 0.0144\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0143 - val_loss: 0.0144\nEpoch 34/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0143 - val_loss: 0.0144\nEpoch 35/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0143 - val_loss: 0.0144\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0143 - val_loss: 0.0144\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0143 - val_loss: 0.0144\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0144\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0144\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0144\nEpoch 41/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0143\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0144\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0144\nEpoch 44/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0144\nEpoch 45/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0143\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0143\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0143\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0143\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0143\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0143\n\nautoencoder training time:  35.899415493011475 \n\n\n  (10000, 25)\n\n  (10000, 25)\n\n KNN training+prediction time:  7.002623796463013  , k =  15 \n\n\n Accuracy score :  0.8475\nEpoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0388 - val_loss: 0.0205\nEpoch 2/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0184 - val_loss: 0.0167\nEpoch 3/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0158 - val_loss: 0.0150\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0145 - val_loss: 0.0142\nEpoch 5/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0137 - val_loss: 0.0136\nEpoch 6/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0132 - val_loss: 0.0130\nEpoch 7/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0131\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0125 - val_loss: 0.0124\nEpoch 9/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0121 - val_loss: 0.0124\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0119 - val_loss: 0.0119\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0117 - val_loss: 0.0117\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0117 - val_loss: 0.0116\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0114\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0112 - val_loss: 0.0114\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0111 - val_loss: 0.0113\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0110 - val_loss: 0.0112\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0109 - val_loss: 0.0110\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0108 - val_loss: 0.0110\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0109\nEpoch 20/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0106 - val_loss: 0.0108\nEpoch 21/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0107\nEpoch 22/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0107\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0104 - val_loss: 0.0106\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0106\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0105\nEpoch 26/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0104\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0105\nEpoch 28/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0105\nEpoch 29/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0104\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0103\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0103\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0102\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0102\nEpoch 34/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0102\nEpoch 35/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0102\nEpoch 36/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0101\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0101\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0097 - val_loss: 0.0102\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0097 - val_loss: 0.0100\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0097 - val_loss: 0.0100\nEpoch 41/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0096 - val_loss: 0.0100\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0096 - val_loss: 0.0100\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0095 - val_loss: 0.0098\nEpoch 44/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0095 - val_loss: 0.0099\nEpoch 45/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0094 - val_loss: 0.0098\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0094 - val_loss: 0.0097\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0094 - val_loss: 0.0098\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0093 - val_loss: 0.0097\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0093 - val_loss: 0.0097\nEpoch 50/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0098\n\nautoencoder training time:  41.90331149101257 \n\n\n  (10000, 25)\n\n  (10000, 25)\n\n KNN training+prediction time:  4.464042663574219  , k =  15 \n\n\n Accuracy score :  0.8574\nEpoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0424 - val_loss: 0.0236\nEpoch 2/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0206 - val_loss: 0.0185\nEpoch 3/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0177 - val_loss: 0.0177\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0160 - val_loss: 0.0155\nEpoch 5/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0150 - val_loss: 0.0146\nEpoch 6/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0141\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0136 - val_loss: 0.0136\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0132 - val_loss: 0.0133\nEpoch 9/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0128 - val_loss: 0.0129\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0126 - val_loss: 0.0126\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0123\nEpoch 12/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0121 - val_loss: 0.0122\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0119 - val_loss: 0.0120\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0117 - val_loss: 0.0118\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0117\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0116\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0116\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0111 - val_loss: 0.0113\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0110 - val_loss: 0.0112\nEpoch 20/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0109 - val_loss: 0.0112\nEpoch 21/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0108 - val_loss: 0.0111\nEpoch 22/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0110\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0109\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0106 - val_loss: 0.0108\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0105 - val_loss: 0.0108\nEpoch 26/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0110\nEpoch 27/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0107\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0106\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0106\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0107\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0105\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0105\nEpoch 33/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0104\nEpoch 34/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0104\nEpoch 35/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0103\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0103\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0104\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0103\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0104\nEpoch 40/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0099 - val_loss: 0.0103\nEpoch 41/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0103\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0102\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0102\nEpoch 44/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0103\nEpoch 45/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0103\nEpoch 46/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0101\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0097 - val_loss: 0.0101\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0097 - val_loss: 0.0101\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0096 - val_loss: 0.0101\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0096 - val_loss: 0.0101\n\nautoencoder training time:  42.01686906814575 \n\n\n  (10000, 25)\n\n  (10000, 25)\n\n KNN training+prediction time:  4.683609247207642  , k =  15 \n\n\n Accuracy score :  0.8581\nEpoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0442 - val_loss: 0.0242\nEpoch 2/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0219 - val_loss: 0.0200\nEpoch 3/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0189 - val_loss: 0.0180\nEpoch 4/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0172 - val_loss: 0.0165\nEpoch 5/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0162 - val_loss: 0.0174\nEpoch 6/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0153 - val_loss: 0.0149\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0146 - val_loss: 0.0143\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0140 - val_loss: 0.0139\nEpoch 9/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0135\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0132 - val_loss: 0.0132\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0128 - val_loss: 0.0129\nEpoch 12/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0125 - val_loss: 0.0126\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0125\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0121 - val_loss: 0.0121\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0119 - val_loss: 0.0119\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0117 - val_loss: 0.0119\nEpoch 17/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0116\nEpoch 18/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0113 - val_loss: 0.0115\nEpoch 19/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0114\nEpoch 20/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0113\nEpoch 21/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0111\nEpoch 22/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0108 - val_loss: 0.0110\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0110\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0106 - val_loss: 0.0109\nEpoch 25/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0106 - val_loss: 0.0108\nEpoch 26/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0104 - val_loss: 0.0109\nEpoch 27/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0107\nEpoch 28/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0103 - val_loss: 0.0108\nEpoch 29/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0103 - val_loss: 0.0106\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0106\nEpoch 31/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0102 - val_loss: 0.0105\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0101 - val_loss: 0.0105\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0104\nEpoch 34/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0103\nEpoch 35/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0103\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0104\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0102\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0103\nEpoch 39/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0102\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0102\nEpoch 41/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0101\nEpoch 42/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0103\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0097 - val_loss: 0.0102\nEpoch 44/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0096 - val_loss: 0.0102\nEpoch 45/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0100\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0096 - val_loss: 0.0100\nEpoch 47/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0100\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0095 - val_loss: 0.0100\nEpoch 49/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0100\nEpoch 50/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0100\n\nautoencoder training time:  44.16706585884094 \n\n\n  (10000, 25)\n\n  (10000, 25)\n\n KNN training+prediction time:  5.915807723999023  , k =  15 \n\n\n Accuracy score :  0.8574\nEpoch 1/50\n235/235 [==============================] - 2s 5ms/step - loss: 0.0482 - val_loss: 0.0281\nEpoch 2/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0247 - val_loss: 0.0223\nEpoch 3/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0211 - val_loss: 0.0201\nEpoch 4/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0192 - val_loss: 0.0184\nEpoch 5/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0181 - val_loss: 0.0175\nEpoch 6/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0172 - val_loss: 0.0169\nEpoch 7/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0165 - val_loss: 0.0165\nEpoch 8/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0159 - val_loss: 0.0160\nEpoch 9/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0154 - val_loss: 0.0153\nEpoch 10/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0150 - val_loss: 0.0150\nEpoch 11/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0147 - val_loss: 0.0146\nEpoch 12/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0144 - val_loss: 0.0145\nEpoch 13/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0141 - val_loss: 0.0142\nEpoch 14/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0139 - val_loss: 0.0138\nEpoch 15/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0136\nEpoch 16/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0133 - val_loss: 0.0140\nEpoch 17/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0131 - val_loss: 0.0132\nEpoch 18/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0131\nEpoch 19/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0126 - val_loss: 0.0128\nEpoch 20/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0128\nEpoch 21/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0124\nEpoch 22/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0126\nEpoch 23/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0120 - val_loss: 0.0124\nEpoch 24/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0119 - val_loss: 0.0122\nEpoch 25/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0118 - val_loss: 0.0120\nEpoch 26/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0120\nEpoch 27/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0120\nEpoch 28/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0118\nEpoch 29/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0116\nEpoch 30/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0113 - val_loss: 0.0115\nEpoch 31/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0112 - val_loss: 0.0116\nEpoch 32/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0112 - val_loss: 0.0115\nEpoch 33/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0111 - val_loss: 0.0114\nEpoch 34/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0113\nEpoch 35/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0117\nEpoch 36/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0113\nEpoch 37/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0113\nEpoch 38/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0107 - val_loss: 0.0111\nEpoch 39/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0107 - val_loss: 0.0111\nEpoch 40/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0106 - val_loss: 0.0112\nEpoch 41/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0110\nEpoch 42/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0111\nEpoch 43/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0104 - val_loss: 0.0108\nEpoch 44/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0108\nEpoch 45/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0103 - val_loss: 0.0111\nEpoch 46/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0103 - val_loss: 0.0108\nEpoch 47/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0103 - val_loss: 0.0108\nEpoch 48/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0102 - val_loss: 0.0107\nEpoch 49/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0102 - val_loss: 0.0109\nEpoch 50/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0102 - val_loss: 0.0107\n\nautoencoder training time:  83.03943634033203 \n\n\n  (10000, 25)\n\n  (10000, 25)\n\n KNN training+prediction time:  4.97918701171875  , k =  15 \n\n\n Accuracy score :  0.8544\n","output_type":"stream"}]},{"cell_type":"code","source":"models_15 = multipleModels(modelDepths_15, x_train,x_val,y_train,y_val)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-05T18:58:31.877948Z","iopub.execute_input":"2021-11-05T18:58:31.878227Z","iopub.status.idle":"2021-11-05T19:04:03.445378Z","shell.execute_reply.started":"2021-11-05T18:58:31.878153Z","shell.execute_reply":"2021-11-05T19:04:03.444625Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0700 - val_loss: 0.0429\nEpoch 2/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0365 - val_loss: 0.0316\nEpoch 3/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0289 - val_loss: 0.0269\nEpoch 4/50\n235/235 [==============================] - 1s 6ms/step - loss: 0.0251 - val_loss: 0.0239\nEpoch 5/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0226 - val_loss: 0.0218\nEpoch 6/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0210 - val_loss: 0.0204\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0200 - val_loss: 0.0197\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0194 - val_loss: 0.0193\nEpoch 9/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0191 - val_loss: 0.0190\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0188 - val_loss: 0.0188\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0187 - val_loss: 0.0187\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - val_loss: 0.0186\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0185 - val_loss: 0.0185\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0184 - val_loss: 0.0185\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0183 - val_loss: 0.0184\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0183 - val_loss: 0.0183\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0182 - val_loss: 0.0183\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0182 - val_loss: 0.0182\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0181 - val_loss: 0.0182\nEpoch 20/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0181 - val_loss: 0.0182\nEpoch 21/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0181 - val_loss: 0.0181\nEpoch 22/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0180 - val_loss: 0.0181\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0180 - val_loss: 0.0181\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0180 - val_loss: 0.0181\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0180 - val_loss: 0.0181\nEpoch 26/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0179 - val_loss: 0.0180\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0179 - val_loss: 0.0180\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0179 - val_loss: 0.0180\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0179 - val_loss: 0.0180\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0179 - val_loss: 0.0179\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0179\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0179\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0179\nEpoch 34/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0178 - val_loss: 0.0179\nEpoch 35/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0179\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0179\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0179\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0179\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0178\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0177 - val_loss: 0.0178\nEpoch 41/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0177 - val_loss: 0.0179\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0177 - val_loss: 0.0178\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0177 - val_loss: 0.0178\nEpoch 44/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0177 - val_loss: 0.0178\nEpoch 45/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0177 - val_loss: 0.0178\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0177 - val_loss: 0.0178\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0177 - val_loss: 0.0178\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0177 - val_loss: 0.0178\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0177 - val_loss: 0.0178\nEpoch 50/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0177 - val_loss: 0.0178\n\nautoencoder training time:  37.32500219345093 \n\n\n  (10000, 15)\n\n  (10000, 15)\n\n KNN training+prediction time:  2.478350877761841  , k =  15 \n\n\n Accuracy score :  0.8294\nEpoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0422 - val_loss: 0.0245\nEpoch 2/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0203 - val_loss: 0.0185\nEpoch 3/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0177 - val_loss: 0.0172\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0165 - val_loss: 0.0161\nEpoch 5/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0159 - val_loss: 0.0155\nEpoch 6/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0152 - val_loss: 0.0152\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0148 - val_loss: 0.0149\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0145 - val_loss: 0.0145\nEpoch 9/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0143\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0140 - val_loss: 0.0141\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0138 - val_loss: 0.0139\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0137 - val_loss: 0.0137\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0135 - val_loss: 0.0137\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0133 - val_loss: 0.0135\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0132 - val_loss: 0.0135\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0130 - val_loss: 0.0131\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0128 - val_loss: 0.0129\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0126 - val_loss: 0.0127\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0125 - val_loss: 0.0127\nEpoch 20/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0125\nEpoch 21/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0125\nEpoch 22/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0122 - val_loss: 0.0125\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0121 - val_loss: 0.0123\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0121 - val_loss: 0.0123\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0120 - val_loss: 0.0122\nEpoch 26/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0119 - val_loss: 0.0122\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0119 - val_loss: 0.0122\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0118 - val_loss: 0.0121\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0118 - val_loss: 0.0120\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0118 - val_loss: 0.0121\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0117 - val_loss: 0.0120\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0117 - val_loss: 0.0120\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0119\nEpoch 34/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0119\nEpoch 35/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0118\nEpoch 36/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0115 - val_loss: 0.0119\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0115 - val_loss: 0.0119\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0115 - val_loss: 0.0118\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0119\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0118\nEpoch 41/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0118\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0118\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0117\nEpoch 44/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0117\nEpoch 45/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0117\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0117\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0112 - val_loss: 0.0116\nEpoch 48/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0117\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0112 - val_loss: 0.0117\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0112 - val_loss: 0.0116\n\nautoencoder training time:  39.49626588821411 \n\n\n  (10000, 15)\n\n  (10000, 15)\n\n KNN training+prediction time:  1.7874610424041748  , k =  15 \n\n\n Accuracy score :  0.8488\nEpoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0418 - val_loss: 0.0230\nEpoch 2/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0208 - val_loss: 0.0189\nEpoch 3/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0175 - val_loss: 0.0167\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0161 - val_loss: 0.0156\nEpoch 5/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0151 - val_loss: 0.0148\nEpoch 6/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0144 - val_loss: 0.0143\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0138 - val_loss: 0.0138\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0135 - val_loss: 0.0133\nEpoch 9/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0131 - val_loss: 0.0131\nEpoch 10/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0129 - val_loss: 0.0128\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0126 - val_loss: 0.0127\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0125 - val_loss: 0.0125\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0124\nEpoch 14/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0121 - val_loss: 0.0124\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0120 - val_loss: 0.0121\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0119 - val_loss: 0.0121\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0118 - val_loss: 0.0119\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0117 - val_loss: 0.0119\nEpoch 19/50\n235/235 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0118\nEpoch 20/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0117\nEpoch 21/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0116\nEpoch 22/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0117\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0112 - val_loss: 0.0115\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0112 - val_loss: 0.0114\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0111 - val_loss: 0.0115\nEpoch 26/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0110 - val_loss: 0.0114\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0110 - val_loss: 0.0113\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0109 - val_loss: 0.0113\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0109 - val_loss: 0.0112\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0108 - val_loss: 0.0112\nEpoch 31/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0113\nEpoch 32/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0111\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0111\nEpoch 34/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0111\nEpoch 35/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0110\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0106 - val_loss: 0.0111\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0106 - val_loss: 0.0110\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0105 - val_loss: 0.0112\nEpoch 39/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0109\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0105 - val_loss: 0.0109\nEpoch 41/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0104 - val_loss: 0.0109\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0104 - val_loss: 0.0108\nEpoch 43/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0110\nEpoch 44/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0104 - val_loss: 0.0109\nEpoch 45/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0108\nEpoch 46/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0103 - val_loss: 0.0107\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0112\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0107\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0107\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0107\n\nautoencoder training time:  41.97535943984985 \n\n\n  (10000, 15)\n\n  (10000, 15)\n\n KNN training+prediction time:  2.91583251953125  , k =  15 \n\n\n Accuracy score :  0.857\nEpoch 1/50\n235/235 [==============================] - 2s 4ms/step - loss: 0.0458 - val_loss: 0.0257\nEpoch 2/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0230 - val_loss: 0.0208\nEpoch 3/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0197 - val_loss: 0.0187\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0180 - val_loss: 0.0176\nEpoch 5/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0170 - val_loss: 0.0167\nEpoch 6/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0162 - val_loss: 0.0160\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0155 - val_loss: 0.0155\nEpoch 8/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0150 - val_loss: 0.0148\nEpoch 9/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0145 - val_loss: 0.0148\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0141 - val_loss: 0.0141\nEpoch 11/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0138 - val_loss: 0.0138\nEpoch 12/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0135\nEpoch 13/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0133 - val_loss: 0.0133\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0131 - val_loss: 0.0131\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0129 - val_loss: 0.0132\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0127 - val_loss: 0.0129\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0126 - val_loss: 0.0127\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0125 - val_loss: 0.0127\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0125\nEpoch 20/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0124\nEpoch 21/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0121 - val_loss: 0.0123\nEpoch 22/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0120 - val_loss: 0.0122\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0119 - val_loss: 0.0123\nEpoch 24/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0118 - val_loss: 0.0121\nEpoch 25/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0120\nEpoch 26/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0120\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0119\nEpoch 28/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0119\nEpoch 29/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0118\nEpoch 30/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0121\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0117\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0116\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0118\nEpoch 34/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0117\nEpoch 35/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0115\nEpoch 36/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0111 - val_loss: 0.0115\nEpoch 37/50\n235/235 [==============================] - 1s 6ms/step - loss: 0.0111 - val_loss: 0.0114\nEpoch 38/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0114\nEpoch 39/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0116\nEpoch 40/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0115\nEpoch 41/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0114\nEpoch 42/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0113\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0108 - val_loss: 0.0113\nEpoch 44/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0112\nEpoch 45/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0108 - val_loss: 0.0114\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0112\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0113\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0111\nEpoch 49/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0107 - val_loss: 0.0112\nEpoch 50/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0106 - val_loss: 0.0112\n\nautoencoder training time:  84.08323359489441 \n\n\n  (10000, 15)\n\n  (10000, 15)\n\n KNN training+prediction time:  2.674354314804077  , k =  15 \n\n\n Accuracy score :  0.8528\nEpoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0518 - val_loss: 0.0318\nEpoch 2/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0271 - val_loss: 0.0237\nEpoch 3/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0223 - val_loss: 0.0212\nEpoch 4/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0207 - val_loss: 0.0202\nEpoch 5/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0195 - val_loss: 0.0190\nEpoch 6/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0186 - val_loss: 0.0186\nEpoch 7/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0177 - val_loss: 0.0174\nEpoch 8/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0170 - val_loss: 0.0168\nEpoch 9/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0165 - val_loss: 0.0162\nEpoch 10/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0160 - val_loss: 0.0160\nEpoch 11/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0157 - val_loss: 0.0157\nEpoch 12/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0154 - val_loss: 0.0154\nEpoch 13/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0151 - val_loss: 0.0151\nEpoch 14/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0149 - val_loss: 0.0152\nEpoch 15/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0146 - val_loss: 0.0146\nEpoch 16/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0144 - val_loss: 0.0148\nEpoch 17/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0143\nEpoch 18/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0142\nEpoch 19/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0138 - val_loss: 0.0140\nEpoch 20/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0141\nEpoch 21/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0140\nEpoch 22/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0134 - val_loss: 0.0136\nEpoch 23/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0133 - val_loss: 0.0135\nEpoch 24/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0132 - val_loss: 0.0133\nEpoch 25/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0130 - val_loss: 0.0132\nEpoch 26/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0129 - val_loss: 0.0133\nEpoch 27/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0129 - val_loss: 0.0134\nEpoch 28/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0133\nEpoch 29/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0127 - val_loss: 0.0130\nEpoch 30/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0126 - val_loss: 0.0129\nEpoch 31/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0125 - val_loss: 0.0129\nEpoch 32/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0125 - val_loss: 0.0128\nEpoch 33/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0128\nEpoch 34/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0126\nEpoch 35/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0127\nEpoch 36/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0126\nEpoch 37/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0121 - val_loss: 0.0125\nEpoch 38/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0120 - val_loss: 0.0125\nEpoch 39/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0120 - val_loss: 0.0123\nEpoch 40/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0119 - val_loss: 0.0124\nEpoch 41/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0119 - val_loss: 0.0123\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0118 - val_loss: 0.0123\nEpoch 43/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0118 - val_loss: 0.0122\nEpoch 44/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0117 - val_loss: 0.0121\nEpoch 45/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0117 - val_loss: 0.0121\nEpoch 46/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0121\nEpoch 47/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0120\nEpoch 48/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0120\nEpoch 49/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0118\nEpoch 50/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0119\n\nautoencoder training time:  46.95771026611328 \n\n\n  (10000, 15)\n\n  (10000, 15)\n\n KNN training+prediction time:  2.0108728408813477  , k =  15 \n\n\n Accuracy score :  0.8402\nEpoch 1/50\n235/235 [==============================] - 2s 6ms/step - loss: 0.0542 - val_loss: 0.0302\nEpoch 2/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0260 - val_loss: 0.0242\nEpoch 3/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0229 - val_loss: 0.0224\nEpoch 4/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0215 - val_loss: 0.0213\nEpoch 5/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0204 - val_loss: 0.0202\nEpoch 6/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0194 - val_loss: 0.0189\nEpoch 7/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0185 - val_loss: 0.0184\nEpoch 8/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0180\nEpoch 9/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0175 - val_loss: 0.0175\nEpoch 10/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0171 - val_loss: 0.0170\nEpoch 11/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0166 - val_loss: 0.0168\nEpoch 12/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0163 - val_loss: 0.0164\nEpoch 13/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0160 - val_loss: 0.0162\nEpoch 14/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0159 - val_loss: 0.0161\nEpoch 15/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0156 - val_loss: 0.0159\nEpoch 16/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0155 - val_loss: 0.0159\nEpoch 17/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0154 - val_loss: 0.0154\nEpoch 18/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0152 - val_loss: 0.0154\nEpoch 19/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0151 - val_loss: 0.0155\nEpoch 20/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0150 - val_loss: 0.0152\nEpoch 21/50\n235/235 [==============================] - 1s 6ms/step - loss: 0.0149 - val_loss: 0.0151\nEpoch 22/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0149 - val_loss: 0.0151\nEpoch 23/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0148 - val_loss: 0.0150\nEpoch 24/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0147 - val_loss: 0.0149\nEpoch 25/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0146 - val_loss: 0.0148\nEpoch 26/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0145 - val_loss: 0.0147\nEpoch 27/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0144 - val_loss: 0.0147\nEpoch 28/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0144 - val_loss: 0.0147\nEpoch 29/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0143 - val_loss: 0.0147\nEpoch 30/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0143 - val_loss: 0.0146\nEpoch 31/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0146\nEpoch 32/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0141 - val_loss: 0.0145\nEpoch 33/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0141 - val_loss: 0.0144\nEpoch 34/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0143\nEpoch 35/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0139 - val_loss: 0.0145\nEpoch 36/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0139 - val_loss: 0.0144\nEpoch 37/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0141\nEpoch 38/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0141\nEpoch 39/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0141\nEpoch 40/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0141\nEpoch 41/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0138\nEpoch 42/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0133 - val_loss: 0.0137\nEpoch 43/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0133 - val_loss: 0.0142\nEpoch 44/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0132 - val_loss: 0.0136\nEpoch 45/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0131 - val_loss: 0.0135\nEpoch 46/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0130 - val_loss: 0.0135\nEpoch 47/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0130 - val_loss: 0.0135\nEpoch 48/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0129 - val_loss: 0.0133\nEpoch 49/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0134\nEpoch 50/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0127 - val_loss: 0.0131\n\nautoencoder training time:  48.51856064796448 \n\n\n  (10000, 15)\n\n  (10000, 15)\n\n KNN training+prediction time:  2.355461835861206  , k =  15 \n\n\n Accuracy score :  0.8335\n","output_type":"stream"}]},{"cell_type":"code","source":"models_5 = multipleModels(modelDepths_5, x_train,x_val,y_train,y_val)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-05T19:04:03.449127Z","iopub.execute_input":"2021-11-05T19:04:03.452453Z","iopub.status.idle":"2021-11-05T19:10:14.323689Z","shell.execute_reply.started":"2021-11-05T19:04:03.452410Z","shell.execute_reply":"2021-11-05T19:10:14.322954Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0878 - val_loss: 0.0560\nEpoch 2/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0422\nEpoch 3/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0400 - val_loss: 0.0381\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0369 - val_loss: 0.0358\nEpoch 5/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0349 - val_loss: 0.0341\nEpoch 6/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0334 - val_loss: 0.0328\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0322 - val_loss: 0.0317\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0314 - val_loss: 0.0310\nEpoch 9/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0308 - val_loss: 0.0305\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0303 - val_loss: 0.0301\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0300 - val_loss: 0.0299\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0298 - val_loss: 0.0296\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0296 - val_loss: 0.0295\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0295 - val_loss: 0.0294\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0294 - val_loss: 0.0293\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0293 - val_loss: 0.0293\nEpoch 17/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0292 - val_loss: 0.0293\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0292 - val_loss: 0.0291\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0291 - val_loss: 0.0291\nEpoch 20/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0291 - val_loss: 0.0291\nEpoch 21/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0291 - val_loss: 0.0290\nEpoch 22/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0290 - val_loss: 0.0290\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0290 - val_loss: 0.0290\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0290 - val_loss: 0.0290\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0290 - val_loss: 0.0290\nEpoch 26/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0290 - val_loss: 0.0290\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0289 - val_loss: 0.0289\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0289 - val_loss: 0.0289\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0289 - val_loss: 0.0290\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0289 - val_loss: 0.0289\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0289 - val_loss: 0.0289\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0289 - val_loss: 0.0289\nEpoch 33/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0289 - val_loss: 0.0289\nEpoch 34/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0289 - val_loss: 0.0289\nEpoch 35/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0289 - val_loss: 0.0288\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0288 - val_loss: 0.0288\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0288 - val_loss: 0.0288\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0288 - val_loss: 0.0289\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0288 - val_loss: 0.0288\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0288 - val_loss: 0.0288\nEpoch 41/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0288 - val_loss: 0.0288\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0288 - val_loss: 0.0288\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0288 - val_loss: 0.0288\nEpoch 44/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0288 - val_loss: 0.0288\nEpoch 45/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0288 - val_loss: 0.0288\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0288 - val_loss: 0.0288\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0288 - val_loss: 0.0288\nEpoch 48/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0288 - val_loss: 0.0288\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0288 - val_loss: 0.0288\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0288 - val_loss: 0.0288\n\nautoencoder training time:  36.96988081932068 \n\n\n  (10000, 5)\n\n  (10000, 5)\n\n KNN training+prediction time:  0.5193819999694824  , k =  15 \n\n\n Accuracy score :  0.7506\nEpoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0577 - val_loss: 0.0324\nEpoch 2/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0284 - val_loss: 0.0263\nEpoch 3/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0255 - val_loss: 0.0249\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0244 - val_loss: 0.0241\nEpoch 5/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0238 - val_loss: 0.0236\nEpoch 6/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0232 - val_loss: 0.0231\nEpoch 7/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0227 - val_loss: 0.0226\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0223 - val_loss: 0.0224\nEpoch 9/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0221 - val_loss: 0.0221\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0218 - val_loss: 0.0219\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0216 - val_loss: 0.0217\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0214 - val_loss: 0.0216\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0212 - val_loss: 0.0214\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0211 - val_loss: 0.0213\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0210 - val_loss: 0.0211\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0209 - val_loss: 0.0211\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0208 - val_loss: 0.0209\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0207 - val_loss: 0.0209\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0206 - val_loss: 0.0209\nEpoch 20/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0205 - val_loss: 0.0207\nEpoch 21/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0205 - val_loss: 0.0206\nEpoch 22/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0204 - val_loss: 0.0206\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0203 - val_loss: 0.0205\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0203 - val_loss: 0.0205\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0202 - val_loss: 0.0205\nEpoch 26/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0202 - val_loss: 0.0205\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0201 - val_loss: 0.0204\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0201 - val_loss: 0.0203\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0200 - val_loss: 0.0203\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0200 - val_loss: 0.0203\nEpoch 31/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0200 - val_loss: 0.0202\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0199 - val_loss: 0.0203\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0199 - val_loss: 0.0201\nEpoch 34/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0198 - val_loss: 0.0201\nEpoch 35/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0198 - val_loss: 0.0201\nEpoch 36/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0198 - val_loss: 0.0200\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0197 - val_loss: 0.0200\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0197 - val_loss: 0.0201\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0197 - val_loss: 0.0200\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0196 - val_loss: 0.0200\nEpoch 41/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0196 - val_loss: 0.0200\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0196 - val_loss: 0.0199\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0196 - val_loss: 0.0198\nEpoch 44/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0195 - val_loss: 0.0200\nEpoch 45/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0195 - val_loss: 0.0199\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0195 - val_loss: 0.0198\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0195 - val_loss: 0.0199\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0194 - val_loss: 0.0198\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0194 - val_loss: 0.0198\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0194 - val_loss: 0.0197\n\nautoencoder training time:  41.92430281639099 \n\n\n  (10000, 5)\n\n  (10000, 5)\n\n KNN training+prediction time:  0.508082389831543  , k =  15 \n\n\n Accuracy score :  0.7832\nEpoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0572 - val_loss: 0.0303\nEpoch 2/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0276 - val_loss: 0.0258\nEpoch 3/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0247 - val_loss: 0.0241\nEpoch 4/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0235 - val_loss: 0.0233\nEpoch 5/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0228 - val_loss: 0.0226\nEpoch 6/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0223 - val_loss: 0.0221\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0217 - val_loss: 0.0217\nEpoch 8/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0214 - val_loss: 0.0214\nEpoch 9/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0211 - val_loss: 0.0212\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0208 - val_loss: 0.0210\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0207 - val_loss: 0.0208\nEpoch 12/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0205 - val_loss: 0.0206\nEpoch 13/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0203 - val_loss: 0.0205\nEpoch 14/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0202 - val_loss: 0.0203\nEpoch 15/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0201 - val_loss: 0.0205\nEpoch 16/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0200 - val_loss: 0.0202\nEpoch 17/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0199 - val_loss: 0.0202\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0198 - val_loss: 0.0200\nEpoch 19/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0197 - val_loss: 0.0200\nEpoch 20/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0196 - val_loss: 0.0199\nEpoch 21/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0196 - val_loss: 0.0199\nEpoch 22/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0195 - val_loss: 0.0198\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0194 - val_loss: 0.0197\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0194 - val_loss: 0.0197\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0193 - val_loss: 0.0196\nEpoch 26/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0193 - val_loss: 0.0196\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0192 - val_loss: 0.0196\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0191 - val_loss: 0.0195\nEpoch 29/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0191 - val_loss: 0.0194\nEpoch 30/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0190 - val_loss: 0.0194\nEpoch 31/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0190 - val_loss: 0.0194\nEpoch 32/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0190 - val_loss: 0.0193\nEpoch 33/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0189 - val_loss: 0.0193\nEpoch 34/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0189 - val_loss: 0.0193\nEpoch 35/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0188 - val_loss: 0.0193\nEpoch 36/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0188 - val_loss: 0.0192\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0188 - val_loss: 0.0192\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0187 - val_loss: 0.0192\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0187 - val_loss: 0.0191\nEpoch 40/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - val_loss: 0.0191\nEpoch 41/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - val_loss: 0.0192\nEpoch 42/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - val_loss: 0.0191\nEpoch 43/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0185 - val_loss: 0.0191\nEpoch 44/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0185 - val_loss: 0.0190\nEpoch 45/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0185 - val_loss: 0.0190\nEpoch 46/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0184 - val_loss: 0.0189\nEpoch 47/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0184 - val_loss: 0.0190\nEpoch 48/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0184 - val_loss: 0.0188\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0183 - val_loss: 0.0188\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0183 - val_loss: 0.0189\n\nautoencoder training time:  41.828052282333374 \n\n\n  (10000, 5)\n\n  (10000, 5)\n\n KNN training+prediction time:  0.5027575492858887  , k =  15 \n\n\n Accuracy score :  0.7898\nEpoch 1/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0802 - val_loss: 0.0517\nEpoch 2/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0420 - val_loss: 0.0355\nEpoch 3/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0332 - val_loss: 0.0314\nEpoch 4/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0305 - val_loss: 0.0298\nEpoch 5/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0292 - val_loss: 0.0286\nEpoch 6/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0282 - val_loss: 0.0277\nEpoch 7/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0274 - val_loss: 0.0269\nEpoch 8/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0263 - val_loss: 0.0260\nEpoch 9/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0257 - val_loss: 0.0256\nEpoch 10/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0253 - val_loss: 0.0251\nEpoch 11/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0250 - val_loss: 0.0249\nEpoch 12/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0247 - val_loss: 0.0247\nEpoch 13/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0245 - val_loss: 0.0245\nEpoch 14/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0243 - val_loss: 0.0244\nEpoch 15/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0241 - val_loss: 0.0242\nEpoch 16/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0240 - val_loss: 0.0241\nEpoch 17/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0238 - val_loss: 0.0239\nEpoch 18/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0237 - val_loss: 0.0238\nEpoch 19/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0235 - val_loss: 0.0236\nEpoch 20/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0234 - val_loss: 0.0236\nEpoch 21/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0232 - val_loss: 0.0233\nEpoch 22/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0231 - val_loss: 0.0232\nEpoch 23/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0229 - val_loss: 0.0230\nEpoch 24/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0228 - val_loss: 0.0230\nEpoch 25/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0227 - val_loss: 0.0231\nEpoch 26/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0226 - val_loss: 0.0228\nEpoch 27/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0225 - val_loss: 0.0226\nEpoch 28/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0224 - val_loss: 0.0226\nEpoch 29/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0223 - val_loss: 0.0226\nEpoch 30/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0223 - val_loss: 0.0224\nEpoch 31/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0222 - val_loss: 0.0224\nEpoch 32/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0221 - val_loss: 0.0223\nEpoch 33/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0220 - val_loss: 0.0223\nEpoch 34/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0219 - val_loss: 0.0222\nEpoch 35/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0218 - val_loss: 0.0220\nEpoch 36/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0218 - val_loss: 0.0220\nEpoch 37/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0217 - val_loss: 0.0219\nEpoch 38/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0216 - val_loss: 0.0219\nEpoch 39/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0216 - val_loss: 0.0218\nEpoch 40/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0215 - val_loss: 0.0218\nEpoch 41/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0215 - val_loss: 0.0217\nEpoch 42/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0214 - val_loss: 0.0216\nEpoch 43/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0213 - val_loss: 0.0216\nEpoch 44/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0213 - val_loss: 0.0216\nEpoch 45/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0212 - val_loss: 0.0215\nEpoch 46/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0212 - val_loss: 0.0215\nEpoch 47/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0211 - val_loss: 0.0214\nEpoch 48/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0211 - val_loss: 0.0215\nEpoch 49/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0211 - val_loss: 0.0214\nEpoch 50/50\n235/235 [==============================] - 1s 3ms/step - loss: 0.0210 - val_loss: 0.0213\n\nautoencoder training time:  43.488816261291504 \n\n\n  (10000, 5)\n\n  (10000, 5)\n\n KNN training+prediction time:  0.4853360652923584  , k =  15 \n\n\n Accuracy score :  0.7666\nEpoch 1/50\n235/235 [==============================] - 2s 4ms/step - loss: 0.0704 - val_loss: 0.0441\nEpoch 2/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0398 - val_loss: 0.0370\nEpoch 3/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0352 - val_loss: 0.0337\nEpoch 4/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0317 - val_loss: 0.0295\nEpoch 5/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0285 - val_loss: 0.0276\nEpoch 6/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0270 - val_loss: 0.0266\nEpoch 7/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0261 - val_loss: 0.0260\nEpoch 8/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0255 - val_loss: 0.0254\nEpoch 9/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0250 - val_loss: 0.0250\nEpoch 10/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0246 - val_loss: 0.0246\nEpoch 11/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0243 - val_loss: 0.0244\nEpoch 12/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0241 - val_loss: 0.0242\nEpoch 13/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0239 - val_loss: 0.0239\nEpoch 14/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0237 - val_loss: 0.0237\nEpoch 15/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0236 - val_loss: 0.0236\nEpoch 16/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0234 - val_loss: 0.0236\nEpoch 17/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0233 - val_loss: 0.0234\nEpoch 18/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0232 - val_loss: 0.0234\nEpoch 19/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0231 - val_loss: 0.0232\nEpoch 20/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0230 - val_loss: 0.0233\nEpoch 21/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0229 - val_loss: 0.0230\nEpoch 22/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0228 - val_loss: 0.0229\nEpoch 23/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0227 - val_loss: 0.0228\nEpoch 24/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0226 - val_loss: 0.0228\nEpoch 25/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0225 - val_loss: 0.0226\nEpoch 26/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0225 - val_loss: 0.0227\nEpoch 27/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0224 - val_loss: 0.0227\nEpoch 28/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0223 - val_loss: 0.0225\nEpoch 29/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0223 - val_loss: 0.0225\nEpoch 30/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0222 - val_loss: 0.0226\nEpoch 31/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0222 - val_loss: 0.0224\nEpoch 32/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0221 - val_loss: 0.0223\nEpoch 33/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0221 - val_loss: 0.0225\nEpoch 34/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0220 - val_loss: 0.0222\nEpoch 35/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0220 - val_loss: 0.0222\nEpoch 36/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0219 - val_loss: 0.0223\nEpoch 37/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0218 - val_loss: 0.0221\nEpoch 38/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0218 - val_loss: 0.0221\nEpoch 39/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0218 - val_loss: 0.0223\nEpoch 40/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0217 - val_loss: 0.0220\nEpoch 41/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0217 - val_loss: 0.0219\nEpoch 42/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0216 - val_loss: 0.0220\nEpoch 43/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0216 - val_loss: 0.0220\nEpoch 44/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0216 - val_loss: 0.0220\nEpoch 45/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0215 - val_loss: 0.0219\nEpoch 46/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0215 - val_loss: 0.0220\nEpoch 47/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0215 - val_loss: 0.0218\nEpoch 48/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0214 - val_loss: 0.0218\nEpoch 49/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0214 - val_loss: 0.0217\nEpoch 50/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0214 - val_loss: 0.0218\n\nautoencoder training time:  46.94908165931702 \n\n\n  (10000, 5)\n\n  (10000, 5)\n\n KNN training+prediction time:  0.46551084518432617  , k =  15 \n\n\n Accuracy score :  0.7485\nEpoch 1/50\n235/235 [==============================] - 2s 5ms/step - loss: 0.0647 - val_loss: 0.0384\nEpoch 2/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0328 - val_loss: 0.0288\nEpoch 3/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0271 - val_loss: 0.0257\nEpoch 4/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0245 - val_loss: 0.0238\nEpoch 5/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0232 - val_loss: 0.0226\nEpoch 6/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0222 - val_loss: 0.0221\nEpoch 7/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0216 - val_loss: 0.0214\nEpoch 8/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0211 - val_loss: 0.0209\nEpoch 9/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0206 - val_loss: 0.0207\nEpoch 10/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0204 - val_loss: 0.0204\nEpoch 11/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0201 - val_loss: 0.0206\nEpoch 12/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0200 - val_loss: 0.0203\nEpoch 13/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0197 - val_loss: 0.0200\nEpoch 14/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0195 - val_loss: 0.0198\nEpoch 15/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0194 - val_loss: 0.0194\nEpoch 16/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0193 - val_loss: 0.0195\nEpoch 17/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0192 - val_loss: 0.0193\nEpoch 18/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0191 - val_loss: 0.0192\nEpoch 19/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0190 - val_loss: 0.0193\nEpoch 20/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0189 - val_loss: 0.0190\nEpoch 21/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0188 - val_loss: 0.0192\nEpoch 22/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0187 - val_loss: 0.0191\nEpoch 23/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0186 - val_loss: 0.0189\nEpoch 24/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0185 - val_loss: 0.0188\nEpoch 25/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0184 - val_loss: 0.0190\nEpoch 26/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0184 - val_loss: 0.0188\nEpoch 27/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0183 - val_loss: 0.0186\nEpoch 28/50\n235/235 [==============================] - 1s 6ms/step - loss: 0.0183 - val_loss: 0.0192\nEpoch 29/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0182 - val_loss: 0.0186\nEpoch 30/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0182 - val_loss: 0.0185\nEpoch 31/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0181 - val_loss: 0.0188\nEpoch 32/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0184\nEpoch 33/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0184\nEpoch 34/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0186\nEpoch 35/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0184\nEpoch 36/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0179 - val_loss: 0.0182\nEpoch 37/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0178 - val_loss: 0.0184\nEpoch 38/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0178 - val_loss: 0.0186\nEpoch 39/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0178 - val_loss: 0.0181\nEpoch 40/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0177 - val_loss: 0.0181\nEpoch 41/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0176 - val_loss: 0.0181\nEpoch 42/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0176 - val_loss: 0.0182\nEpoch 43/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0176 - val_loss: 0.0182\nEpoch 44/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0176 - val_loss: 0.0181\nEpoch 45/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0175 - val_loss: 0.0183\nEpoch 46/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0175 - val_loss: 0.0179\nEpoch 47/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0174 - val_loss: 0.0180\nEpoch 48/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0174 - val_loss: 0.0181\nEpoch 49/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0174 - val_loss: 0.0179\nEpoch 50/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0174 - val_loss: 0.0180\n\nautoencoder training time:  83.07477712631226 \n\n\n  (10000, 5)\n\n  (10000, 5)\n\n KNN training+prediction time:  0.5118944644927979  , k =  15 \n\n\n Accuracy score :  0.8029\nEpoch 1/50\n235/235 [==============================] - 2s 5ms/step - loss: 0.0754 - val_loss: 0.0411\nEpoch 2/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0363 - val_loss: 0.0339\nEpoch 3/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0323 - val_loss: 0.0314\nEpoch 4/50\n235/235 [==============================] - 1s 6ms/step - loss: 0.0302 - val_loss: 0.0296\nEpoch 5/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0286 - val_loss: 0.0274\nEpoch 6/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0266 - val_loss: 0.0259\nEpoch 7/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0254 - val_loss: 0.0248\nEpoch 8/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0245 - val_loss: 0.0241\nEpoch 9/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0239 - val_loss: 0.0236\nEpoch 10/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0234 - val_loss: 0.0231\nEpoch 11/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0230 - val_loss: 0.0232\nEpoch 12/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0228 - val_loss: 0.0228\nEpoch 13/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0226 - val_loss: 0.0225\nEpoch 14/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0224 - val_loss: 0.0224\nEpoch 15/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0222 - val_loss: 0.0224\nEpoch 16/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0221 - val_loss: 0.0222\nEpoch 17/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0219 - val_loss: 0.0222\nEpoch 18/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0218 - val_loss: 0.0220\nEpoch 19/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0216 - val_loss: 0.0219\nEpoch 20/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0215 - val_loss: 0.0216\nEpoch 21/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0215 - val_loss: 0.0216\nEpoch 22/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0213 - val_loss: 0.0216\nEpoch 23/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0212 - val_loss: 0.0216\nEpoch 24/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0213 - val_loss: 0.0229\nEpoch 25/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0212 - val_loss: 0.0214\nEpoch 26/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0211 - val_loss: 0.0214\nEpoch 27/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0209 - val_loss: 0.0215\nEpoch 28/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0208 - val_loss: 0.0212\nEpoch 29/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0208 - val_loss: 0.0211\nEpoch 30/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0208 - val_loss: 0.0211\nEpoch 31/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0208 - val_loss: 0.0210\nEpoch 32/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0206 - val_loss: 0.0211\nEpoch 33/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0210 - val_loss: 0.0212\nEpoch 34/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0208 - val_loss: 0.0211\nEpoch 35/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0206 - val_loss: 0.0209\nEpoch 36/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0205 - val_loss: 0.0208\nEpoch 37/50\n235/235 [==============================] - 1s 6ms/step - loss: 0.0205 - val_loss: 0.0209\nEpoch 38/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0205 - val_loss: 0.0209\nEpoch 39/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0203 - val_loss: 0.0208\nEpoch 40/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0203 - val_loss: 0.0206\nEpoch 41/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0203 - val_loss: 0.0208\nEpoch 42/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0202 - val_loss: 0.0205\nEpoch 43/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0202 - val_loss: 0.0205\nEpoch 44/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0202 - val_loss: 0.0206\nEpoch 45/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0203 - val_loss: 0.0209\nEpoch 46/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0202 - val_loss: 0.0205\nEpoch 47/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0200 - val_loss: 0.0204\nEpoch 48/50\n235/235 [==============================] - 1s 5ms/step - loss: 0.0201 - val_loss: 0.0208\nEpoch 49/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0201 - val_loss: 0.0204\nEpoch 50/50\n235/235 [==============================] - 1s 4ms/step - loss: 0.0201 - val_loss: 0.0204\n\nautoencoder training time:  51.808351278305054 \n\n\n  (10000, 5)\n\n  (10000, 5)\n\n KNN training+prediction time:  0.43646693229675293  , k =  15 \n\n\n Accuracy score :  0.7703\n","output_type":"stream"}]},{"cell_type":"code","source":"all_models = [models_5,models_15,models_25, models_50, models_75, models_100]","metadata":{"execution":{"iopub.status.busy":"2021-11-05T19:10:14.326347Z","iopub.execute_input":"2021-11-05T19:10:14.326698Z","iopub.status.idle":"2021-11-05T19:10:14.331261Z","shell.execute_reply.started":"2021-11-05T19:10:14.326658Z","shell.execute_reply":"2021-11-05T19:10:14.330418Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#performance df con 1 columna por modelo\n\nmodel_depth = []\nlatentDims = []\nmodel_classif_time = []\nmodel_red_time = []\nmodel_classif_acc = []\nmodel_loss = []\nfor models in all_models:\n  for model in models:\n    model_depth.append(len(model.hDims))\n    latentDims.append(model.lDim)\n    model_classif_time.append(model.classifierTimePerformances[0])\n    model_red_time.append(model.reductionTimePerformance)\n    model_classif_acc.append(model.classifierAccuracyPerformances[0])\ndf_performances = pd.DataFrame([model_depth,latentDims,\nmodel_classif_time,\nmodel_red_time,\nmodel_classif_acc]).T\ndf_performances.columns=['# hidden', 'latent dim', 't_classif', 't_red','acc']\nprint(df_performances)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-05T19:10:14.332449Z","iopub.execute_input":"2021-11-05T19:10:14.333442Z","iopub.status.idle":"2021-11-05T19:10:14.360667Z","shell.execute_reply.started":"2021-11-05T19:10:14.333405Z","shell.execute_reply":"2021-11-05T19:10:14.359888Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"    # hidden  latent dim  t_classif      t_red     acc\n0        1.0         5.0   0.519382  36.969881  0.7506\n1        3.0         5.0   0.508082  41.924303  0.7832\n2        5.0         5.0   0.502758  41.828052  0.7898\n3        7.0         5.0   0.485336  43.488816  0.7666\n4        9.0         5.0   0.465511  46.949082  0.7485\n5       11.0         5.0   0.511894  83.074777  0.8029\n6       13.0         5.0   0.436467  51.808351  0.7703\n7        1.0        15.0   2.478351  37.325002  0.8294\n8        3.0        15.0   1.787461  39.496266  0.8488\n9        5.0        15.0   2.915833  41.975359  0.8570\n10       7.0        15.0   2.674354  84.083234  0.8528\n11       9.0        15.0   2.010873  46.957710  0.8402\n12      11.0        15.0   2.355462  48.518561  0.8335\n13       1.0        25.0   7.002624  35.899415  0.8475\n14       3.0        25.0   4.464043  41.903311  0.8574\n15       5.0        25.0   4.683609  42.016869  0.8581\n16       7.0        25.0   5.915808  44.167066  0.8574\n17       9.0        25.0   4.979187  83.039436  0.8544\n18       1.0        50.0  23.635928  41.854524  0.8536\n19       3.0        50.0  20.407004  40.053424  0.8632\n20       5.0        50.0  28.124051  41.628927  0.8652\n21       7.0        50.0  19.403607  44.604663  0.8664\n22       9.0        50.0  16.479418  46.616480  0.8610\n23       1.0        75.0  38.836747  41.847050  0.8546\n24       3.0        75.0  52.503715  42.092988  0.8643\n25       5.0        75.0  61.300675  42.707890  0.8684\n26       7.0        75.0  69.892645  82.993826  0.8715\n27       9.0        75.0  47.554794  46.709029  0.8679\n28       1.0       100.0  67.112664  36.253248  0.8563\n29       3.0       100.0  76.678835  42.135509  0.8589\n30       5.0       100.0  76.476752  39.964832  0.8657\n","output_type":"stream"}]},{"cell_type":"code","source":"df_performances.to_csv(\"performances.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2021-11-05T19:23:00.802183Z","iopub.execute_input":"2021-11-05T19:23:00.802507Z","iopub.status.idle":"2021-11-05T19:23:00.809110Z","shell.execute_reply.started":"2021-11-05T19:23:00.802475Z","shell.execute_reply":"2021-11-05T19:23:00.808360Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Analisis de los Resultados:\n\n-(hecho)tiempo de clasificacion en funcion del espacio latente (un histograma por espacio)  \n-(hecho)accuracy en funcion del espacio latente y el numero de capas (superficie)  \n-(hecho)tiempo de reduccion en funcion del numero de capas y el espacio latente  \n-misma profundidad, distintas dimensiones  \nconclusiones (chequear): mas profundidad (a mismo espacio latente) -> mas accuracy  \n                                                pero tambien -> mas t-reduccion  \n                         menor dimension -> menor t-clasif  \n                         \n                         ","metadata":{}},{"cell_type":"code","source":"df_performances = pd.read_csv(\"./performances.csv\")\ndf_performances.rename(columns ={\"latent dim\":\"latent_dim\", \"# hidden\": \"nHidden\"}, inplace=True)\n\ndfs = []\nfor k in [5,15,25,50,75,100]:\n     dfs.append(df_performances[df_performances[\"latent_dim\"]== k])","metadata":{"execution":{"iopub.status.busy":"2021-11-05T19:10:14.372749Z","iopub.execute_input":"2021-11-05T19:10:14.373567Z","iopub.status.idle":"2021-11-05T19:10:14.392509Z","shell.execute_reply.started":"2021-11-05T19:10:14.373528Z","shell.execute_reply":"2021-11-05T19:10:14.391734Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df_performances","metadata":{"execution":{"iopub.status.busy":"2021-11-05T19:22:49.267056Z","iopub.execute_input":"2021-11-05T19:22:49.267343Z","iopub.status.idle":"2021-11-05T19:22:49.289386Z","shell.execute_reply.started":"2021-11-05T19:22:49.267290Z","shell.execute_reply":"2021-11-05T19:22:49.288560Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"    Unnamed: 0  nHidden  latent_dim  t_classif      t_red     acc\n0            0      1.0         5.0   0.519382  36.969881  0.7506\n1            1      3.0         5.0   0.508082  41.924303  0.7832\n2            2      5.0         5.0   0.502758  41.828052  0.7898\n3            3      7.0         5.0   0.485336  43.488816  0.7666\n4            4      9.0         5.0   0.465511  46.949082  0.7485\n5            5     11.0         5.0   0.511894  83.074777  0.8029\n6            6     13.0         5.0   0.436467  51.808351  0.7703\n7            7      1.0        15.0   2.478351  37.325002  0.8294\n8            8      3.0        15.0   1.787461  39.496266  0.8488\n9            9      5.0        15.0   2.915833  41.975359  0.8570\n10          10      7.0        15.0   2.674354  84.083234  0.8528\n11          11      9.0        15.0   2.010873  46.957710  0.8402\n12          12     11.0        15.0   2.355462  48.518561  0.8335\n13          13      1.0        25.0   7.002624  35.899415  0.8475\n14          14      3.0        25.0   4.464043  41.903311  0.8574\n15          15      5.0        25.0   4.683609  42.016869  0.8581\n16          16      7.0        25.0   5.915808  44.167066  0.8574\n17          17      9.0        25.0   4.979187  83.039436  0.8544\n18          18      1.0        50.0  23.635928  41.854524  0.8536\n19          19      3.0        50.0  20.407004  40.053424  0.8632\n20          20      5.0        50.0  28.124051  41.628927  0.8652\n21          21      7.0        50.0  19.403607  44.604663  0.8664\n22          22      9.0        50.0  16.479418  46.616480  0.8610\n23          23      1.0        75.0  38.836747  41.847050  0.8546\n24          24      3.0        75.0  52.503715  42.092988  0.8643\n25          25      5.0        75.0  61.300675  42.707890  0.8684\n26          26      7.0        75.0  69.892645  82.993826  0.8715\n27          27      9.0        75.0  47.554794  46.709029  0.8679\n28          28      1.0       100.0  67.112664  36.253248  0.8563\n29          29      3.0       100.0  76.678835  42.135509  0.8589\n30          30      5.0       100.0  76.476752  39.964832  0.8657","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>nHidden</th>\n      <th>latent_dim</th>\n      <th>t_classif</th>\n      <th>t_red</th>\n      <th>acc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0.519382</td>\n      <td>36.969881</td>\n      <td>0.7506</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>0.508082</td>\n      <td>41.924303</td>\n      <td>0.7832</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.502758</td>\n      <td>41.828052</td>\n      <td>0.7898</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>0.485336</td>\n      <td>43.488816</td>\n      <td>0.7666</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>0.465511</td>\n      <td>46.949082</td>\n      <td>0.7485</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>11.0</td>\n      <td>5.0</td>\n      <td>0.511894</td>\n      <td>83.074777</td>\n      <td>0.8029</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>13.0</td>\n      <td>5.0</td>\n      <td>0.436467</td>\n      <td>51.808351</td>\n      <td>0.7703</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>1.0</td>\n      <td>15.0</td>\n      <td>2.478351</td>\n      <td>37.325002</td>\n      <td>0.8294</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>3.0</td>\n      <td>15.0</td>\n      <td>1.787461</td>\n      <td>39.496266</td>\n      <td>0.8488</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>5.0</td>\n      <td>15.0</td>\n      <td>2.915833</td>\n      <td>41.975359</td>\n      <td>0.8570</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>7.0</td>\n      <td>15.0</td>\n      <td>2.674354</td>\n      <td>84.083234</td>\n      <td>0.8528</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>9.0</td>\n      <td>15.0</td>\n      <td>2.010873</td>\n      <td>46.957710</td>\n      <td>0.8402</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>11.0</td>\n      <td>15.0</td>\n      <td>2.355462</td>\n      <td>48.518561</td>\n      <td>0.8335</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>1.0</td>\n      <td>25.0</td>\n      <td>7.002624</td>\n      <td>35.899415</td>\n      <td>0.8475</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>3.0</td>\n      <td>25.0</td>\n      <td>4.464043</td>\n      <td>41.903311</td>\n      <td>0.8574</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>5.0</td>\n      <td>25.0</td>\n      <td>4.683609</td>\n      <td>42.016869</td>\n      <td>0.8581</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>7.0</td>\n      <td>25.0</td>\n      <td>5.915808</td>\n      <td>44.167066</td>\n      <td>0.8574</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>9.0</td>\n      <td>25.0</td>\n      <td>4.979187</td>\n      <td>83.039436</td>\n      <td>0.8544</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>1.0</td>\n      <td>50.0</td>\n      <td>23.635928</td>\n      <td>41.854524</td>\n      <td>0.8536</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>20.407004</td>\n      <td>40.053424</td>\n      <td>0.8632</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>5.0</td>\n      <td>50.0</td>\n      <td>28.124051</td>\n      <td>41.628927</td>\n      <td>0.8652</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>7.0</td>\n      <td>50.0</td>\n      <td>19.403607</td>\n      <td>44.604663</td>\n      <td>0.8664</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>9.0</td>\n      <td>50.0</td>\n      <td>16.479418</td>\n      <td>46.616480</td>\n      <td>0.8610</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>1.0</td>\n      <td>75.0</td>\n      <td>38.836747</td>\n      <td>41.847050</td>\n      <td>0.8546</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>3.0</td>\n      <td>75.0</td>\n      <td>52.503715</td>\n      <td>42.092988</td>\n      <td>0.8643</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>5.0</td>\n      <td>75.0</td>\n      <td>61.300675</td>\n      <td>42.707890</td>\n      <td>0.8684</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>7.0</td>\n      <td>75.0</td>\n      <td>69.892645</td>\n      <td>82.993826</td>\n      <td>0.8715</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>9.0</td>\n      <td>75.0</td>\n      <td>47.554794</td>\n      <td>46.709029</td>\n      <td>0.8679</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>28</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>67.112664</td>\n      <td>36.253248</td>\n      <td>0.8563</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>29</td>\n      <td>3.0</td>\n      <td>100.0</td>\n      <td>76.678835</td>\n      <td>42.135509</td>\n      <td>0.8589</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>30</td>\n      <td>5.0</td>\n      <td>100.0</td>\n      <td>76.476752</td>\n      <td>39.964832</td>\n      <td>0.8657</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport numpy as np\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-11-05T19:10:14.422627Z","iopub.execute_input":"2021-11-05T19:10:14.423042Z","iopub.status.idle":"2021-11-05T19:10:14.429373Z","shell.execute_reply.started":"2021-11-05T19:10:14.423006Z","shell.execute_reply":"2021-11-05T19:10:14.428362Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfig, axs = plt.subplots(2,3)\nfig.suptitle(\"Tiempos de reduccion para cada espacio latente \\n\")\nfig.set_figheight(10)\nfig.set_figwidth(13)\nfig.tight_layout(pad=5.0)\ni = 0\nl = [5,15,25,50,75,100]\nfor ax in axs:\n    for a in ax:\n        a.set_xlabel(\"Capas ocultas\")\n        a.set_ylabel(\"Tiempo\")\n        a.set_title(\"Dim. Latente: \" + str(l[i]))\n        a.bar(dfs[i][\"nHidden\"].astype(int).astype(str),height=dfs[i][\"t_red\"])\n        i = i + 1\n        \"\"\"\nticks = np.arange(0,1,0.05)\nformats = df_performances.pivot(\"latent_dim\",\"nHidden\",\"t_red\")\nformats.plot(kind='bar',figsize=(13,8),xlabel=\"Dimension\", ylabel = \"Tiempo (s)\", title=\"tiempo de reduccion por espacio latente\")\nplt.savefig(\"t-red-lat\")","metadata":{"execution":{"iopub.status.busy":"2021-11-05T19:37:58.795163Z","iopub.execute_input":"2021-11-05T19:37:58.795695Z","iopub.status.idle":"2021-11-05T19:37:59.264776Z","shell.execute_reply.started":"2021-11-05T19:37:58.795656Z","shell.execute_reply":"2021-11-05T19:37:59.264092Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 936x576 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"ticks = np.arange(0,1,0.05)\nformats = df_performances.pivot(\"latent_dim\",\"nHidden\",\"acc\")\nformats.plot(kind='bar',figsize=(13,8),xlabel=\"Dimension\", ylabel = \"accuracy\", yticks = ticks,ylim=(0,0.9), title=\"Accuracy por espacio latente\")\nplt.savefig(\"acc-lat\")","metadata":{"execution":{"iopub.status.busy":"2021-11-05T19:38:19.423926Z","iopub.execute_input":"2021-11-05T19:38:19.424221Z","iopub.status.idle":"2021-11-05T19:38:19.962837Z","shell.execute_reply.started":"2021-11-05T19:38:19.424181Z","shell.execute_reply":"2021-11-05T19:38:19.962127Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 936x576 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"formats = df_performances.pivot(\"latent_dim\",\"nHidden\",\"t_classif\")\nformats.plot(kind='bar',figsize=(13,8),xlabel=\"Dimension\", ylabel = \"Tiempo (s)\",title=\"Tiempo de clasificacion por espacio latente\")\nplt.savefig(\"t-train-lat\")","metadata":{"execution":{"iopub.status.busy":"2021-11-05T19:38:46.081287Z","iopub.execute_input":"2021-11-05T19:38:46.081987Z","iopub.status.idle":"2021-11-05T19:38:46.562844Z","shell.execute_reply.started":"2021-11-05T19:38:46.081947Z","shell.execute_reply":"2021-11-05T19:38:46.562118Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 936x576 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"## Observaciones:\n1. El espacio latente parece no influir en el tiempo de entrenamiento del autoencoder (leves bajadas al subir la dimension).\n2. Mayor profundidad tiende a un mayor tiempo de entrenamiento del autoencoder (con un par de excepciones).\n3. A mayor espacio latente, leve aumento en el accuracy (osea que se logro disminuir la dimension significativamente preservandose la mayoria de la informacion).\n4. No parece haber una relacion directa entre profundidad de la red y la variacion del accuracy.\n5. Drasticas reducciones en el tiempo de clasificacion.","metadata":{"execution":{"iopub.status.busy":"2021-11-05T19:20:34.795117Z","iopub.execute_input":"2021-11-05T19:20:34.795382Z","iopub.status.idle":"2021-11-05T19:20:34.803553Z","shell.execute_reply.started":"2021-11-05T19:20:34.795354Z","shell.execute_reply":"2021-11-05T19:20:34.802662Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}